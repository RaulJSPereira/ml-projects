{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and pandas\n",
    "# Import categorical encoding, necessary layers and Model from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set some parameters:\n",
    "# m  = number of training examples,\n",
    "# dt = total number of pixels,\n",
    "# d  = number of pixels on dimension of the matrix (square root of d2),\n",
    "# n  = number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42000, 784, 28, 10]\n"
     ]
    }
   ],
   "source": [
    "m=train.shape[0]\n",
    "dt=train.shape[1]-1\n",
    "d=int(np.sqrt(dt))\n",
    "n=len(train.label.value_counts())\n",
    "print([m,dt,d,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check that neither the training nor the test sets have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns[pd.concat([train.drop('label',axis=1),test]).isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check that there is an even distribution of training examples across the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some statistics on the pixel values. \n",
    "# I compute Pixel_stats for each pixel, using all training example. \n",
    "# Then I get statistics for each Pixel_stat.\n",
    "# For example, the minimum value for each pixel is always 0, but the maximum value is not always 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pixel_mean</th>\n",
       "      <th>Pixel_std</th>\n",
       "      <th>Pixel_min</th>\n",
       "      <th>Pixel_25%</th>\n",
       "      <th>Pixel_50%</th>\n",
       "      <th>Pixel_75%</th>\n",
       "      <th>Pixel_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.408911</td>\n",
       "      <td>49.307334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.241709</td>\n",
       "      <td>62.629145</td>\n",
       "      <td>217.676020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.573157</td>\n",
       "      <td>44.174709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.240031</td>\n",
       "      <td>99.211592</td>\n",
       "      <td>83.830621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.129470</td>\n",
       "      <td>4.626490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.231500</td>\n",
       "      <td>36.771597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.034262</td>\n",
       "      <td>100.692231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>153.187500</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>139.826143</td>\n",
       "      <td>113.850143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pixel_mean   Pixel_std  Pixel_min  Pixel_25%   Pixel_50%   Pixel_75%  \\\n",
       "mean   33.408911   49.307334        0.0        0.0   12.241709   62.629145   \n",
       "std    42.573157   44.174709        0.0        0.0   33.240031   99.211592   \n",
       "min     0.000000    0.000000        0.0        0.0    0.000000    0.000000   \n",
       "25%     0.129470    4.626490        0.0        0.0    0.000000    0.000000   \n",
       "50%     7.231500   36.771597        0.0        0.0    0.000000    0.000000   \n",
       "75%    69.034262  100.692231        0.0        0.0    0.000000  153.187500   \n",
       "max   139.826143  113.850143        0.0        0.0  173.000000  253.000000   \n",
       "\n",
       "       Pixel_max  \n",
       "mean  217.676020  \n",
       "std    83.830621  \n",
       "min     0.000000  \n",
       "25%   255.000000  \n",
       "50%   255.000000  \n",
       "75%   255.000000  \n",
       "max   255.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('label',axis=1).describe().T.drop('count',axis=1).describe().drop('count',axis=0).add_prefix('Pixel_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I get the dataset ready for usage with keras.\n",
    "# Max: maximum pixel value in the training dataset\n",
    "# x: array of pixel values from training dataset, normalized by Max\n",
    "# y: labels transformed into n-dimensional array\n",
    "# x_test: array of pixel values from test dataset, normalized by Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(42000, 784), 1.0, (42000, 10)]\n",
      "[(28000, 784), 1.0]\n"
     ]
    }
   ],
   "source": [
    "Max=train.max().max()\n",
    "x=train.iloc[:,1:].values/Max\n",
    "y=to_categorical(train.label,n)\n",
    "x_test=test.values/Max\n",
    "print([x.shape,x.max(),y.shape])\n",
    "print([x_test.shape,x_test.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check that the categorical encoding of y with '1' at position 'i' of the n-dim array corresponds to label 'i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[set(train.label[np.argmax(y,axis=1)==i])=={i} for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a fully connected network.\n",
    "# Each hidden layer uses ReLU as activation function, and I use dropout after each of them for regularization\n",
    "# The number of neurons in each layer is given by the input array dims\n",
    "# The output layer has n neurons and uses softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseModel(dims,dropout_rate):\n",
    "    X_input=Input(shape=(dt))\n",
    "    X=X_input\n",
    "    for dim in dims:\n",
    "        X=Dense(dim,activation='relu')(X)\n",
    "        X=Dropout(dropout_rate)(X)\n",
    "    X_output=Dense(n,activation='softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=X_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first model I create has 5 hidden layers with dimensions (392, 196, 196, 98, 98), and 35% dropout rate.\n",
    "# I fit the model with 20 epochs of training, batch size of 128 examples, and 20% of the dataset left for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 196)               77028     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 196)               38612     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 98)                9702      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                990       \n",
      "=================================================================\n",
      "Total params: 453,358\n",
      "Trainable params: 453,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dims=[dt//2,dt//4,dt//4,dt//8,dt//8]\n",
    "model1=DenseModel(dims,0.35)\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.8913 - accuracy: 0.6996 - val_loss: 0.2332 - val_accuracy: 0.9336\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.3041 - accuracy: 0.9207 - val_loss: 0.1626 - val_accuracy: 0.9564\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.2292 - accuracy: 0.9410 - val_loss: 0.1459 - val_accuracy: 0.9606\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 0.1865 - accuracy: 0.9516 - val_loss: 0.1289 - val_accuracy: 0.9652\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.1655 - accuracy: 0.9581 - val_loss: 0.1237 - val_accuracy: 0.9670\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 0.1443 - accuracy: 0.9628 - val_loss: 0.1250 - val_accuracy: 0.9701\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 3s 11ms/step - loss: 0.1260 - accuracy: 0.9676 - val_loss: 0.1347 - val_accuracy: 0.9668\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.1140 - accuracy: 0.9695 - val_loss: 0.1096 - val_accuracy: 0.9739\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 0.1065 - accuracy: 0.9718 - val_loss: 0.1091 - val_accuracy: 0.9725\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 0.0970 - accuracy: 0.9747 - val_loss: 0.1059 - val_accuracy: 0.9739\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 0.0932 - accuracy: 0.9754 - val_loss: 0.1396 - val_accuracy: 0.9724\n",
      "Epoch 12/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0882 - accuracy: 0.9754 - val_loss: 0.1118 - val_accuracy: 0.9765\n",
      "Epoch 13/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0836 - accuracy: 0.9776 - val_loss: 0.0980 - val_accuracy: 0.9767\n",
      "Epoch 14/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0788 - accuracy: 0.9796 - val_loss: 0.0959 - val_accuracy: 0.9777\n",
      "Epoch 15/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0715 - accuracy: 0.9814 - val_loss: 0.1198 - val_accuracy: 0.9758\n",
      "Epoch 16/20\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 0.0709 - accuracy: 0.9815 - val_loss: 0.1066 - val_accuracy: 0.9756\n",
      "Epoch 17/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0694 - accuracy: 0.9810 - val_loss: 0.1093 - val_accuracy: 0.9769\n",
      "Epoch 18/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0679 - accuracy: 0.9818 - val_loss: 0.1131 - val_accuracy: 0.9760\n",
      "Epoch 19/20\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 0.0646 - accuracy: 0.9831 - val_loss: 0.1152 - val_accuracy: 0.9769\n",
      "Epoch 20/20\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 0.0636 - accuracy: 0.9835 - val_loss: 0.1049 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ec65370>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x,y,batch_size=128,epochs=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I set the prediction to the the class with the highest probability in the output layer (softmax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=pd.DataFrame({'ImageId':range(1,len(x_test)+1),'Label':model1.predict(x_test).argmax(axis=1)}).set_index('ImageId')\n",
    "pred1.to_csv('pred1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second model has 7 hidden layers with dimensions (784, 784, 392, 392, 196, 196, 98), and 35% dropout rate.\n",
    "# I fit the model with 25 epochs of training, batch size of 128 examples, and 20% of the dataset left for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 392)               154056    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 196)               77028     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 196)               38612     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                990       \n",
      "=================================================================\n",
      "Total params: 1,828,592\n",
      "Trainable params: 1,828,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dims=[dt,dt,dt//2,dt//2,dt//4,dt//4,dt//8]\n",
    "model2=DenseModel(dims,0.35)\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "263/263 [==============================] - 8s 29ms/step - loss: 0.9188 - accuracy: 0.6856 - val_loss: 0.2254 - val_accuracy: 0.9426\n",
      "Epoch 2/25\n",
      "263/263 [==============================] - 8s 29ms/step - loss: 0.2857 - accuracy: 0.9308 - val_loss: 0.1631 - val_accuracy: 0.9606\n",
      "Epoch 3/25\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.2111 - accuracy: 0.9504 - val_loss: 0.1388 - val_accuracy: 0.9665\n",
      "Epoch 4/25\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.1796 - accuracy: 0.9579 - val_loss: 0.1379 - val_accuracy: 0.9665\n",
      "Epoch 5/25\n",
      "263/263 [==============================] - 7s 28ms/step - loss: 0.1563 - accuracy: 0.9629 - val_loss: 0.1214 - val_accuracy: 0.9698\n",
      "Epoch 6/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.1310 - accuracy: 0.9687 - val_loss: 0.1386 - val_accuracy: 0.9686\n",
      "Epoch 7/25\n",
      "263/263 [==============================] - 9s 34ms/step - loss: 0.1261 - accuracy: 0.9716 - val_loss: 0.1134 - val_accuracy: 0.9745\n",
      "Epoch 8/25\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 0.1102 - accuracy: 0.9750 - val_loss: 0.1284 - val_accuracy: 0.9729\n",
      "Epoch 9/25\n",
      "263/263 [==============================] - 9s 35ms/step - loss: 0.1057 - accuracy: 0.9751 - val_loss: 0.1137 - val_accuracy: 0.9750\n",
      "Epoch 10/25\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0982 - accuracy: 0.9766 - val_loss: 0.1266 - val_accuracy: 0.9715\n",
      "Epoch 11/25\n",
      "263/263 [==============================] - 8s 29ms/step - loss: 0.0974 - accuracy: 0.9764 - val_loss: 0.1292 - val_accuracy: 0.9713\n",
      "Epoch 12/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0900 - accuracy: 0.9786 - val_loss: 0.1233 - val_accuracy: 0.9752\n",
      "Epoch 13/25\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0813 - accuracy: 0.9803 - val_loss: 0.1085 - val_accuracy: 0.9769\n",
      "Epoch 14/25\n",
      "263/263 [==============================] - 9s 36ms/step - loss: 0.0785 - accuracy: 0.9812 - val_loss: 0.1062 - val_accuracy: 0.9764\n",
      "Epoch 15/25\n",
      "263/263 [==============================] - 7s 28ms/step - loss: 0.0719 - accuracy: 0.9828 - val_loss: 0.1341 - val_accuracy: 0.9754\n",
      "Epoch 16/25\n",
      "263/263 [==============================] - 9s 32ms/step - loss: 0.0773 - accuracy: 0.9818 - val_loss: 0.1160 - val_accuracy: 0.9758\n",
      "Epoch 17/25\n",
      "263/263 [==============================] - 9s 35ms/step - loss: 0.0735 - accuracy: 0.9830 - val_loss: 0.1063 - val_accuracy: 0.9786\n",
      "Epoch 18/25\n",
      "263/263 [==============================] - 8s 30ms/step - loss: 0.0618 - accuracy: 0.9854 - val_loss: 0.1358 - val_accuracy: 0.9774\n",
      "Epoch 19/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0665 - accuracy: 0.9842 - val_loss: 0.1421 - val_accuracy: 0.9758\n",
      "Epoch 20/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0665 - accuracy: 0.9846 - val_loss: 0.1152 - val_accuracy: 0.9776\n",
      "Epoch 21/25\n",
      "263/263 [==============================] - 8s 32ms/step - loss: 0.0560 - accuracy: 0.9860 - val_loss: 0.1440 - val_accuracy: 0.9767\n",
      "Epoch 22/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0519 - accuracy: 0.9877 - val_loss: 0.1353 - val_accuracy: 0.9782\n",
      "Epoch 23/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0644 - accuracy: 0.9857 - val_loss: 0.1116 - val_accuracy: 0.9770\n",
      "Epoch 24/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0540 - accuracy: 0.9862 - val_loss: 0.1396 - val_accuracy: 0.9780\n",
      "Epoch 25/25\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 0.0569 - accuracy: 0.9873 - val_loss: 0.1417 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147458d90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x,y,batch_size=128,epochs=25,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=pd.DataFrame({'ImageId':range(1,len(x_test)+1),'Label':model2.predict(x_test).argmax(axis=1)}).set_index('ImageId')\n",
    "pred2.to_csv('pred2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check that almost 2% of the predictions differ compared with the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.980321\n",
       "False    0.019679\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2.join(pred1, lsuffix='1',rsuffix='2').apply(lambda x: x.Label1==x.Label2,axis=1).value_counts()/len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third model has 9 hidden layers, dimensions are (784, 784, 784, 392, 392, 392, 196, 196, 196), and 35% dropout rate.\n",
    "# I fit the model with 30 epochs of training, batch size of 128 examples, and 20% of the dataset left for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 392)               154056    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 392)               154056    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 196)               77028     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 196)               38612     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 196)               38612     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                1970      \n",
      "=================================================================\n",
      "Total params: 2,618,374\n",
      "Trainable params: 2,618,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dims=[dt,dt,dt,dt//2,dt//2,dt//2,dt//4,dt//4,dt//4]\n",
    "model3=DenseModel(dims,0.35)\n",
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "263/263 [==============================] - 15s 56ms/step - loss: 1.3537 - accuracy: 0.4872 - val_loss: 0.3547 - val_accuracy: 0.8770\n",
      "Epoch 2/30\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.3706 - accuracy: 0.9076 - val_loss: 0.2177 - val_accuracy: 0.9486\n",
      "Epoch 3/30\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.2583 - accuracy: 0.9397 - val_loss: 0.1725 - val_accuracy: 0.9615\n",
      "Epoch 4/30\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.2067 - accuracy: 0.9519 - val_loss: 0.1862 - val_accuracy: 0.9573\n",
      "Epoch 5/30\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.1882 - accuracy: 0.9580 - val_loss: 0.1368 - val_accuracy: 0.9679\n",
      "Epoch 6/30\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.1627 - accuracy: 0.9623 - val_loss: 0.1540 - val_accuracy: 0.9673\n",
      "Epoch 7/30\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 0.1543 - accuracy: 0.9651 - val_loss: 0.1356 - val_accuracy: 0.9689\n",
      "Epoch 8/30\n",
      "263/263 [==============================] - 12s 46ms/step - loss: 0.1343 - accuracy: 0.9696 - val_loss: 0.1328 - val_accuracy: 0.9698\n",
      "Epoch 9/30\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 0.1317 - accuracy: 0.9705 - val_loss: 0.1265 - val_accuracy: 0.9721\n",
      "Epoch 10/30\n",
      "263/263 [==============================] - 15s 57ms/step - loss: 0.1086 - accuracy: 0.9745 - val_loss: 0.1161 - val_accuracy: 0.9752\n",
      "Epoch 11/30\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.1134 - accuracy: 0.9751 - val_loss: 0.1260 - val_accuracy: 0.9732\n",
      "Epoch 12/30\n",
      "263/263 [==============================] - 14s 53ms/step - loss: 0.1117 - accuracy: 0.9752 - val_loss: 0.1329 - val_accuracy: 0.9705\n",
      "Epoch 13/30\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 0.1070 - accuracy: 0.9772 - val_loss: 0.1243 - val_accuracy: 0.9733\n",
      "Epoch 14/30\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.1047 - accuracy: 0.9772 - val_loss: 0.1383 - val_accuracy: 0.9726\n",
      "Epoch 15/30\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 0.0987 - accuracy: 0.9787 - val_loss: 0.1307 - val_accuracy: 0.9732\n",
      "Epoch 16/30\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.0956 - accuracy: 0.9785 - val_loss: 0.1481 - val_accuracy: 0.9718\n",
      "Epoch 17/30\n",
      "263/263 [==============================] - 13s 51ms/step - loss: 0.0876 - accuracy: 0.9804 - val_loss: 0.1159 - val_accuracy: 0.9771\n",
      "Epoch 18/30\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 0.0894 - accuracy: 0.9794 - val_loss: 0.1289 - val_accuracy: 0.9754\n",
      "Epoch 19/30\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 0.0832 - accuracy: 0.9812 - val_loss: 0.1287 - val_accuracy: 0.9761\n",
      "Epoch 20/30\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 0.0777 - accuracy: 0.9822 - val_loss: 0.1630 - val_accuracy: 0.9749\n",
      "Epoch 21/30\n",
      "263/263 [==============================] - 14s 54ms/step - loss: 0.0772 - accuracy: 0.9835 - val_loss: 0.1188 - val_accuracy: 0.9774\n",
      "Epoch 22/30\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 0.0796 - accuracy: 0.9835 - val_loss: 0.1380 - val_accuracy: 0.9726\n",
      "Epoch 23/30\n",
      "263/263 [==============================] - 14s 51ms/step - loss: 0.0771 - accuracy: 0.9829 - val_loss: 0.1283 - val_accuracy: 0.9768\n",
      "Epoch 24/30\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 0.0671 - accuracy: 0.9849 - val_loss: 0.1189 - val_accuracy: 0.9789\n",
      "Epoch 25/30\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0715 - accuracy: 0.9849 - val_loss: 0.1022 - val_accuracy: 0.9774\n",
      "Epoch 26/30\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 0.0717 - accuracy: 0.9849 - val_loss: 0.1194 - val_accuracy: 0.9756\n",
      "Epoch 27/30\n",
      "263/263 [==============================] - 11s 42ms/step - loss: 0.0651 - accuracy: 0.9850 - val_loss: 0.1232 - val_accuracy: 0.9777\n",
      "Epoch 28/30\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 0.0562 - accuracy: 0.9878 - val_loss: 0.1271 - val_accuracy: 0.9777\n",
      "Epoch 29/30\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0713 - accuracy: 0.9846 - val_loss: 0.1485 - val_accuracy: 0.9765\n",
      "Epoch 30/30\n",
      "263/263 [==============================] - 13s 49ms/step - loss: 0.0739 - accuracy: 0.9845 - val_loss: 0.1707 - val_accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f608ac0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x,y,batch_size=128,epochs=30,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3=pd.DataFrame({'ImageId':range(1,len(x_test)+1),'Label':model3.predict(x_test).argmax(axis=1)}).set_index('ImageId')\n",
    "pred3.to_csv('pred3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check that almost 2.5% of the predictions differ compared with both model 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.975929\n",
       "False    0.024071\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3.join(pred1, lsuffix='1',rsuffix='2').apply(lambda x: x.Label1==x.Label2,axis=1).value_counts()/len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.975036\n",
       "False    0.024964\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3.join(pred2, lsuffix='1',rsuffix='2').apply(lambda x: x.Label1==x.Label2,axis=1).value_counts()/len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I create the datasets for convolutional neural networks\n",
    "# x_conv: 28 by 28 array of pixel values from training dataset, normalized by Max\n",
    "# x_conv_test: 28 by 28 array of pixel values from test dataset, normalized by Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(42000, 28, 28, 1), 1.0]\n",
      "[(28000, 28, 28, 1), 1.0]\n"
     ]
    }
   ],
   "source": [
    "x_conv=train.values[:,1:].reshape((m,d,d,1))/Max\n",
    "x_conv_test=test.values.reshape((-1,d,d,1))/Max\n",
    "print([x_conv.shape,x_conv.max()])\n",
    "print([x_conv_test.shape,x_conv_test.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a convolutional neural network.\n",
    "# Each hidden layer uses ReLU as activation function, and I use dropout after each of them for regularization\n",
    "# The number of filters in each convolutional layer, the kernel sizes and strides are given as input arrays\n",
    "# I use square filters, with the same stride on both dimensions. I always use 'same' padding\n",
    "# After convolutional layers I flatten and apply a fully connected layer, with dimension given as input\n",
    "# The output layer has n neurons and uses softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvModel(dims,kernels,strides,dim_dense,dropout_rate):\n",
    "    data=np.array([dims,kernels,strides]).T\n",
    "    X_input=Input(shape=(d,d,1))\n",
    "    X=X_input\n",
    "    for dim,kernel,stride in data:\n",
    "        X=Conv2D(dim,kernel_size=(kernel,kernel),strides=(stride,stride),padding='same',activation='relu')(X)\n",
    "        X=Dropout(dropout_rate)(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(dim_dense,activation='relu')(X)\n",
    "    X_output=Dense(n,activation='softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=X_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generically I increase the number of filters as I reduce the size of the matrices. All kernels are 3x3.\n",
    "# I start with 28x28x1 and go to 14x14x32 with a stride of 2.\n",
    "# I then use 'same' padding and unit stride to stay with 14x14 window, but increase to 64 filters\n",
    "# Finally I use stride of 2 again to go to 7x7x128.\n",
    "# I use 128 neurons in the hidden dense layer.\n",
    "# I fit the model with 15 epochs of training, 35% dropout, and 20% of the dataset left for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 896,906\n",
      "Trainable params: 896,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convmodel1=ConvModel([32,64,128],[3,3,3],[2,1,2],128,0.35)\n",
    "convmodel1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "convmodel1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 0.3503 - accuracy: 0.8931 - val_loss: 0.0960 - val_accuracy: 0.9677\n",
      "Epoch 2/15\n",
      "263/263 [==============================] - 35s 133ms/step - loss: 0.1030 - accuracy: 0.9688 - val_loss: 0.0594 - val_accuracy: 0.9804\n",
      "Epoch 3/15\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 0.0759 - accuracy: 0.9761 - val_loss: 0.0485 - val_accuracy: 0.9850\n",
      "Epoch 4/15\n",
      "263/263 [==============================] - 34s 129ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.0465 - val_accuracy: 0.9851\n",
      "Epoch 5/15\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 0.0495 - accuracy: 0.9840 - val_loss: 0.0389 - val_accuracy: 0.9874\n",
      "Epoch 6/15\n",
      "263/263 [==============================] - 32s 124ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0445 - val_accuracy: 0.9856\n",
      "Epoch 7/15\n",
      "263/263 [==============================] - 31s 118ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0395 - val_accuracy: 0.9893\n",
      "Epoch 8/15\n",
      "263/263 [==============================] - 31s 119ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.0367 - val_accuracy: 0.9887\n",
      "Epoch 9/15\n",
      "263/263 [==============================] - 37s 141ms/step - loss: 0.0285 - accuracy: 0.9907 - val_loss: 0.0367 - val_accuracy: 0.9894\n",
      "Epoch 10/15\n",
      "263/263 [==============================] - 32s 122ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0369 - val_accuracy: 0.9901\n",
      "Epoch 11/15\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0382 - val_accuracy: 0.9886\n",
      "Epoch 12/15\n",
      "263/263 [==============================] - 32s 120ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.0378 - val_accuracy: 0.9892\n",
      "Epoch 13/15\n",
      "263/263 [==============================] - 33s 126ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0397 - val_accuracy: 0.9886\n",
      "Epoch 14/15\n",
      "263/263 [==============================] - 33s 127ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
      "Epoch 15/15\n",
      "263/263 [==============================] - 34s 128ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0411 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141b37fd0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel1.fit(x_conv,y_conv,batch_size=128,epochs=15,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpred1=pd.DataFrame({'ImageId':range(1,len(x_conv_test)+1),'Label':convmodel1.predict(x_conv_test).argmax(axis=1)}).set_index('ImageId')\n",
    "convpred1.to_csv('convpred1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use more hidden layers, but still all kernels are 3x3.\n",
    "# Number of filters is 32,64 and 128, twice each. \n",
    "# I half the size of the window every two layers (to 14x14, 7x7 and 4x4)\n",
    "# I use 256 neurons in the hidden dense layer.\n",
    "# I fit the model with 20 epochs of training, 35% dropout, and 20% of the dataset left for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 813,546\n",
      "Trainable params: 813,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convmodel2=ConvModel([32,32,64,64,128,128],[3,3,3,3,3,3],[2,1,2,1,2,1],256,0.35)\n",
    "convmodel2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "convmodel2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 0.5554 - accuracy: 0.8110 - val_loss: 0.1132 - val_accuracy: 0.9643\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 46s 175ms/step - loss: 0.1605 - accuracy: 0.9493 - val_loss: 0.0755 - val_accuracy: 0.9750\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 0.1201 - accuracy: 0.9609 - val_loss: 0.0618 - val_accuracy: 0.9786\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 43s 163ms/step - loss: 0.0985 - accuracy: 0.9689 - val_loss: 0.0492 - val_accuracy: 0.9836\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 43s 165ms/step - loss: 0.0863 - accuracy: 0.9739 - val_loss: 0.0489 - val_accuracy: 0.9821\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 0.0793 - accuracy: 0.9757 - val_loss: 0.0461 - val_accuracy: 0.9843\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 0.0705 - accuracy: 0.9779 - val_loss: 0.0446 - val_accuracy: 0.9846\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 0.0688 - accuracy: 0.9773 - val_loss: 0.0454 - val_accuracy: 0.9860\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0374 - val_accuracy: 0.9877\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 41s 157ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0423 - val_accuracy: 0.9857\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 42s 158ms/step - loss: 0.0556 - accuracy: 0.9820 - val_loss: 0.0349 - val_accuracy: 0.9892\n",
      "Epoch 12/20\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 0.0332 - val_accuracy: 0.9896\n",
      "Epoch 13/20\n",
      "263/263 [==============================] - 44s 166ms/step - loss: 0.0503 - accuracy: 0.9834 - val_loss: 0.0329 - val_accuracy: 0.9906\n",
      "Epoch 14/20\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 0.0463 - accuracy: 0.9851 - val_loss: 0.0343 - val_accuracy: 0.9893\n",
      "Epoch 15/20\n",
      "263/263 [==============================] - 46s 174ms/step - loss: 0.0451 - accuracy: 0.9849 - val_loss: 0.0411 - val_accuracy: 0.9869\n",
      "Epoch 16/20\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 0.0433 - accuracy: 0.9866 - val_loss: 0.0417 - val_accuracy: 0.9885\n",
      "Epoch 17/20\n",
      "263/263 [==============================] - 44s 169ms/step - loss: 0.0397 - accuracy: 0.9868 - val_loss: 0.0366 - val_accuracy: 0.9904\n",
      "Epoch 18/20\n",
      "263/263 [==============================] - 44s 168ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 0.0359 - val_accuracy: 0.9899\n",
      "Epoch 19/20\n",
      "263/263 [==============================] - 46s 173ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.0359 - val_accuracy: 0.9899\n",
      "Epoch 20/20\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.0304 - val_accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141f60c40>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel2.fit(x_conv,y_conv,batch_size=128,epochs=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpred2=pd.DataFrame({'ImageId':range(1,len(x_conv_test)+1),'Label':convmodel2.predict(x_conv_test).argmax(axis=1)}).set_index('ImageId')\n",
    "convpred2.to_csv('convpred2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I try a simpler network now, with just two concolutional layers, dimensions are 32 and 64, windows 14x14 and 7x7.\n",
    "# Dense layer with 128 neurons. I use 13 epochs of training, 35% dropout rate, and 20% train/dev partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convmodel3=ConvModel([32,64],[3,3],[2,2],128,0.35)\n",
    "convmodel3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "convmodel3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 0.4417 - accuracy: 0.8694 - val_loss: 0.1500 - val_accuracy: 0.9555\n",
      "Epoch 2/13\n",
      "263/263 [==============================] - 9s 34ms/step - loss: 0.1568 - accuracy: 0.9527 - val_loss: 0.0940 - val_accuracy: 0.9710\n",
      "Epoch 3/13\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 0.1080 - accuracy: 0.9662 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
      "Epoch 4/13\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 0.0832 - accuracy: 0.9728 - val_loss: 0.0570 - val_accuracy: 0.9813\n",
      "Epoch 5/13\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.0608 - val_accuracy: 0.9799\n",
      "Epoch 6/13\n",
      "263/263 [==============================] - 10s 36ms/step - loss: 0.0601 - accuracy: 0.9807 - val_loss: 0.0460 - val_accuracy: 0.9852\n",
      "Epoch 7/13\n",
      "263/263 [==============================] - 9s 34ms/step - loss: 0.0520 - accuracy: 0.9837 - val_loss: 0.0492 - val_accuracy: 0.9835\n",
      "Epoch 8/13\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.0504 - val_accuracy: 0.9837\n",
      "Epoch 9/13\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0451 - val_accuracy: 0.9854\n",
      "Epoch 10/13\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0388 - val_accuracy: 0.9889\n",
      "Epoch 11/13\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0406 - val_accuracy: 0.9877\n",
      "Epoch 12/13\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.0406 - val_accuracy: 0.9870\n",
      "Epoch 13/13\n",
      "263/263 [==============================] - 10s 39ms/step - loss: 0.0285 - accuracy: 0.9907 - val_loss: 0.0413 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14309f4f0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel3.fit(x_conv,y_conv,batch_size=128,epochs=13,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpred3=pd.DataFrame({'ImageId':range(1,len(x_conv_test)+1),'Label':convmodel3.predict(x_conv_test).argmax(axis=1)}).set_index('ImageId')\n",
    "convpred3.to_csv('convpred3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a new convolutional neural network, with batch normalization layers between convolution and activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvModel2(dims,kernels,strides,dim_dense,dropout_rate):\n",
    "    data=np.array([dims,kernels,strides]).T\n",
    "    X_input=Input(shape=(d,d,1))\n",
    "    X=X_input\n",
    "    for dim,kernel,stride in data:\n",
    "        X=Conv2D(dim,kernel_size=(kernel,kernel),strides=(stride,stride),padding='same',use_bias=False)(X)\n",
    "        X=BatchNormalization()(X)\n",
    "        X=Activation('relu')(X)\n",
    "        X=Dropout(dropout_rate)(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(dim_dense,use_bias=False)(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X_output=Dense(n,activation='softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=X_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like Convolutional model 1 (4 hidden layers), but with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 14, 14, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 7, 7, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 128)               802816    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 897,962\n",
      "Trainable params: 897,258\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convmodel4=ConvModel2([32,64,128],[3,3,3],[2,1,2],128,0.35)\n",
    "convmodel4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "convmodel4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 0.2973 - accuracy: 0.9125 - val_loss: 1.1990 - val_accuracy: 0.6181\n",
      "Epoch 2/15\n",
      "263/263 [==============================] - 46s 177ms/step - loss: 0.0945 - accuracy: 0.9722 - val_loss: 0.0983 - val_accuracy: 0.9700\n",
      "Epoch 3/15\n",
      "263/263 [==============================] - 45s 172ms/step - loss: 0.0665 - accuracy: 0.9801 - val_loss: 0.0460 - val_accuracy: 0.9855\n",
      "Epoch 4/15\n",
      "263/263 [==============================] - 41s 154ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.0388 - val_accuracy: 0.9874\n",
      "Epoch 5/15\n",
      "263/263 [==============================] - 40s 152ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 0.0321 - val_accuracy: 0.9895\n",
      "Epoch 6/15\n",
      "263/263 [==============================] - 40s 153ms/step - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.0318 - val_accuracy: 0.9892\n",
      "Epoch 7/15\n",
      "263/263 [==============================] - 48s 184ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.0340 - val_accuracy: 0.9898\n",
      "Epoch 8/15\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.0336 - val_accuracy: 0.9896\n",
      "Epoch 9/15\n",
      "263/263 [==============================] - 45s 171ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0354 - val_accuracy: 0.9894\n",
      "Epoch 10/15\n",
      "263/263 [==============================] - 49s 188ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0296 - val_accuracy: 0.9921\n",
      "Epoch 11/15\n",
      "263/263 [==============================] - 48s 182ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0301 - val_accuracy: 0.9911\n",
      "Epoch 12/15\n",
      "263/263 [==============================] - 45s 170ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0286 - val_accuracy: 0.9923\n",
      "Epoch 13/15\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0303 - val_accuracy: 0.9913\n",
      "Epoch 14/15\n",
      "263/263 [==============================] - 43s 163ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0336 - val_accuracy: 0.9907\n",
      "Epoch 15/15\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0310 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x108ac3640>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel4.fit(x_conv,y_conv,batch_size=128,epochs=15,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpred4=pd.DataFrame({'ImageId':range(1,len(x_conv_test)+1),'Label':convmodel4.predict(x_conv_test).argmax(axis=1)}).set_index('ImageId')\n",
    "convpred4.to_csv('convpred4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like Convolutional model 2 (7 hidden layers), but with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 14, 14, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 14, 14, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 7, 64)          18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 64)          36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 4, 4, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 4, 4, 128)         147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 256)               524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 815,658\n",
      "Trainable params: 814,250\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convmodel5=ConvModel2([32,32,64,64,128,128],[3,3,3,3,3,3],[2,1,2,1,2,1],256,0.35)\n",
    "convmodel5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "convmodel5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "263/263 [==============================] - 58s 220ms/step - loss: 0.6265 - accuracy: 0.7922 - val_loss: 0.3228 - val_accuracy: 0.9006\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 58s 222ms/step - loss: 0.1764 - accuracy: 0.9438 - val_loss: 0.0847 - val_accuracy: 0.9723\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 52s 199ms/step - loss: 0.1290 - accuracy: 0.9585 - val_loss: 0.0608 - val_accuracy: 0.9780\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 0.1055 - accuracy: 0.9661 - val_loss: 0.0445 - val_accuracy: 0.9840\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 52s 197ms/step - loss: 0.0911 - accuracy: 0.9708 - val_loss: 0.0428 - val_accuracy: 0.9861\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 0.0795 - accuracy: 0.9744 - val_loss: 0.0408 - val_accuracy: 0.9869\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 57s 216ms/step - loss: 0.0739 - accuracy: 0.9761 - val_loss: 0.0404 - val_accuracy: 0.9867\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 47s 180ms/step - loss: 0.0656 - accuracy: 0.9779 - val_loss: 0.0348 - val_accuracy: 0.9880\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 53s 201ms/step - loss: 0.0625 - accuracy: 0.9801 - val_loss: 0.0384 - val_accuracy: 0.9879\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 49s 185ms/step - loss: 0.0574 - accuracy: 0.9809 - val_loss: 0.0337 - val_accuracy: 0.9899\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 57s 217ms/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 0.0347 - val_accuracy: 0.9889\n",
      "Epoch 12/20\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 0.0526 - accuracy: 0.9824 - val_loss: 0.0338 - val_accuracy: 0.9896\n",
      "Epoch 13/20\n",
      "263/263 [==============================] - 58s 220ms/step - loss: 0.0481 - accuracy: 0.9839 - val_loss: 0.0330 - val_accuracy: 0.9892\n",
      "Epoch 14/20\n",
      "263/263 [==============================] - 57s 218ms/step - loss: 0.0456 - accuracy: 0.9846 - val_loss: 0.0460 - val_accuracy: 0.9863\n",
      "Epoch 15/20\n",
      "263/263 [==============================] - 52s 200ms/step - loss: 0.0440 - accuracy: 0.9855 - val_loss: 0.0334 - val_accuracy: 0.9906\n",
      "Epoch 16/20\n",
      "263/263 [==============================] - 57s 218ms/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 0.0309 - val_accuracy: 0.9904\n",
      "Epoch 17/20\n",
      "263/263 [==============================] - 63s 240ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0332 - val_accuracy: 0.9905\n",
      "Epoch 18/20\n",
      "263/263 [==============================] - 59s 225ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.0285 - val_accuracy: 0.9911\n",
      "Epoch 19/20\n",
      "263/263 [==============================] - 56s 215ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.0333 - val_accuracy: 0.9905\n",
      "Epoch 20/20\n",
      "263/263 [==============================] - 73s 279ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.0293 - val_accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1475dd1c0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel5.fit(x_conv,y_conv,batch_size=128,epochs=20,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpred5=pd.DataFrame({'ImageId':range(1,len(x_conv_test)+1),'Label':convmodel5.predict(x_conv_test).argmax(axis=1)}).set_index('ImageId')\n",
    "convpred5.to_csv('convpred5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, I create yet a third type of model, where there is a pooling layer between activation and dropout.\n",
    "# The idea is that I will now be able to decrease the window size with pooling instead of using wider strides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvModel3(dims,kernels,strides,pools,dim_dense,dropout_rate):\n",
    "    data=np.array([dims,kernels,strides,pools]).T\n",
    "    X_input=Input(shape=(d,d,1))\n",
    "    X=X_input\n",
    "    for dim,kernel,stride,pool in data:\n",
    "        X=Conv2D(dim,kernel_size=(kernel,kernel),strides=(stride,stride),padding='same',use_bias=False)(X)\n",
    "        X=BatchNormalization()(X)\n",
    "        X=Activation('relu')(X)\n",
    "        X=MaxPooling2D(pool_size=(pool,pool))(X)\n",
    "        X=Dropout(dropout_rate)(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(dim_dense,use_bias=False)(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=Activation('relu')(X)\n",
    "    X_output=Dense(n,activation='softmax')(X)\n",
    "    model=Model(inputs=X_input,outputs=X_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like Convolutional model 1 (4 hidden layers), but with batch normalization and pooling.\n",
    "# All strides are set to 1, and I pool with 2x2 filters after each convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 28, 28, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 14, 14, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 7, 7, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 242,602\n",
      "Trainable params: 241,898\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convmodel6=ConvModel3([32,64,128],[3,3,3],[1,1,1],[2,2,2],128,0.35)\n",
    "convmodel6.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "convmodel6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "263/263 [==============================] - 55s 208ms/step - loss: 0.4329 - accuracy: 0.8691 - val_loss: 6.2019 - val_accuracy: 0.1131\n",
      "Epoch 2/15\n",
      "263/263 [==============================] - 55s 207ms/step - loss: 0.1207 - accuracy: 0.9632 - val_loss: 0.8730 - val_accuracy: 0.7287\n",
      "Epoch 3/15\n",
      "263/263 [==============================] - 54s 205ms/step - loss: 0.0864 - accuracy: 0.9730 - val_loss: 0.0535 - val_accuracy: 0.9831\n",
      "Epoch 4/15\n",
      "263/263 [==============================] - 60s 229ms/step - loss: 0.0727 - accuracy: 0.9778 - val_loss: 0.0448 - val_accuracy: 0.9854\n",
      "Epoch 5/15\n",
      "263/263 [==============================] - 59s 224ms/step - loss: 0.0619 - accuracy: 0.9804 - val_loss: 0.0331 - val_accuracy: 0.9899\n",
      "Epoch 6/15\n",
      "263/263 [==============================] - 58s 220ms/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.0318 - val_accuracy: 0.9912\n",
      "Epoch 7/15\n",
      "263/263 [==============================] - 59s 225ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0394 - val_accuracy: 0.9880\n",
      "Epoch 8/15\n",
      "263/263 [==============================] - 54s 204ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.0360 - val_accuracy: 0.9895\n",
      "Epoch 9/15\n",
      "263/263 [==============================] - 60s 229ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0289 - val_accuracy: 0.9914\n",
      "Epoch 10/15\n",
      "263/263 [==============================] - 50s 189ms/step - loss: 0.0413 - accuracy: 0.9864 - val_loss: 0.0286 - val_accuracy: 0.9914\n",
      "Epoch 11/15\n",
      "263/263 [==============================] - 54s 204ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 12/15\n",
      "263/263 [==============================] - 55s 209ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.0272 - val_accuracy: 0.9908\n",
      "Epoch 13/15\n",
      "263/263 [==============================] - 55s 207ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.0302 - val_accuracy: 0.9917\n",
      "Epoch 14/15\n",
      "263/263 [==============================] - 54s 206ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0290 - val_accuracy: 0.9917\n",
      "Epoch 15/15\n",
      "263/263 [==============================] - 53s 202ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.0270 - val_accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a2f6a60>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel6.fit(x_conv,y_conv,batch_size=128,epochs=15,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "convpred6=pd.DataFrame({'ImageId':range(1,len(x_conv_test)+1),'Label':convmodel6.predict(x_conv_test).argmax(axis=1)}).set_index('ImageId')\n",
    "convpred6.to_csv('convpred6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
